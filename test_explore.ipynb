{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import scipy.stats as scs\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from multiprocessing import pool\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data from DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import explore file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from explore import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make mh dfs and dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mh_anx dfs and (md - for comparing users * includes all posts)\n",
    "\n",
    "mh_anx_post, mh_anx_user, md = make_mh_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make pc dfs and update dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc_anx_post, pc_anx_user, md = make_pc_df(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge dfs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anx_post, anx_user = merge_df(mh_anx_post, pc_anx_post, mh_anx_user, pc_anx_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check out dfs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>user</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post</th>\n",
       "      <th>post_type</th>\n",
       "      <th>mood</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>forum_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1592723</td>\n",
       "      <td>Andy1963</td>\n",
       "      <td>Sudden Onset Anxiety - Please help!</td>\n",
       "      <td>hi ive never suffered any sort of anxiety befo...</td>\n",
       "      <td>author</td>\n",
       "      <td>nan</td>\n",
       "      <td>Sudden Onset Anxiety - Please help!</td>\n",
       "      <td>Generalized Anxiety Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1592736</td>\n",
       "      <td>Zardos</td>\n",
       "      <td>nan</td>\n",
       "      <td>i can sympathize i get crippling anxiety when ...</td>\n",
       "      <td>responder</td>\n",
       "      <td>nan</td>\n",
       "      <td>Sudden Onset Anxiety - Please help!</td>\n",
       "      <td>Generalized Anxiety Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1594183</td>\n",
       "      <td>rachelangelo</td>\n",
       "      <td>nan</td>\n",
       "      <td>im sorry youre dealing with this i dont know i...</td>\n",
       "      <td>responder</td>\n",
       "      <td>nan</td>\n",
       "      <td>Sudden Onset Anxiety - Please help!</td>\n",
       "      <td>Generalized Anxiety Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1598245</td>\n",
       "      <td>akash</td>\n",
       "      <td>nan</td>\n",
       "      <td>apart from medical help there are many tricks ...</td>\n",
       "      <td>responder</td>\n",
       "      <td>nan</td>\n",
       "      <td>Sudden Onset Anxiety - Please help!</td>\n",
       "      <td>Generalized Anxiety Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>585119</td>\n",
       "      <td>Mayfair</td>\n",
       "      <td>nan</td>\n",
       "      <td>great tune  i had my beatles number one hits i...</td>\n",
       "      <td>responder</td>\n",
       "      <td>nan</td>\n",
       "      <td>didnt know where to post this</td>\n",
       "      <td>Social Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pid           user                           post_title  \\\n",
       "0  1592723      Andy1963   Sudden Onset Anxiety - Please help!   \n",
       "1  1592736        Zardos                                   nan   \n",
       "2  1594183  rachelangelo                                   nan   \n",
       "3  1598245         akash                                   nan   \n",
       "4   585119       Mayfair                                   nan   \n",
       "\n",
       "                                                post  post_type mood  \\\n",
       "0  hi ive never suffered any sort of anxiety befo...     author  nan   \n",
       "1  i can sympathize i get crippling anxiety when ...  responder  nan   \n",
       "2  im sorry youre dealing with this i dont know i...  responder  nan   \n",
       "3  apart from medical help there are many tricks ...  responder  nan   \n",
       "4  great tune  i had my beatles number one hits i...  responder  nan   \n",
       "\n",
       "                          thread_title                    forum_name  \n",
       "0  Sudden Onset Anxiety - Please help!  Generalized Anxiety Disorder  \n",
       "1  Sudden Onset Anxiety - Please help!  Generalized Anxiety Disorder  \n",
       "2  Sudden Onset Anxiety - Please help!  Generalized Anxiety Disorder  \n",
       "3  Sudden Onset Anxiety - Please help!  Generalized Anxiety Disorder  \n",
       "4        didnt know where to post this                Social Anxiety  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anx_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>member_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>steviep43</td>\n",
       "      <td>Jan 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chalmers333</td>\n",
       "      <td>Jan 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JenIAm</td>\n",
       "      <td>Jan 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aw3092</td>\n",
       "      <td>Jan 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>srussells</td>\n",
       "      <td>Jan 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user member_since\n",
       "0    steviep43      Jan 2018\n",
       "1  Chalmers333      Jan 2018\n",
       "2       JenIAm      Jan 2018\n",
       "3       Aw3092      Jan 2018\n",
       "4    srussells      Jan 2017"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anx_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create docs and labels\n",
    "\n",
    "users, docs = make_docs_labels(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create vectorizer instance\n",
    "# vectorize docs\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "vect = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickling for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib the model\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vect.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib the matrix\n",
    "joblib.dump(vect, \"vect.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the model with joblib\n",
    "\n",
    "test = joblib.load(\"vect.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['md.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(md, \"md.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = joblib.load(\"md.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing a query to users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = [key for key in md]\n",
    "documents = [md[user] for user in users]\n",
    "docs = [\" \".join(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = ['hi ive been suffering for anxiety for some time. i experience a weird dread that comes over me at night. im okay during the day but it gets really overwhelming at night']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = vectorizer.fit_transform(docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_vect = vectorizer.transform(query).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_sim = linear_kernel(vect, query_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_sims = np.argsort(cos_sim, axis = None)[-1:-7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2635,    0, 2554, 6009, 3530,  360])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can pull out users using these indices\n",
    "top_sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating user list for each post\n",
    "users = [anx_post['user'][i] for i in anx_post.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating post list\n",
    "posts = [anx_post['post'][i] for i in anx_post.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorizing\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 1000)\n",
    "vect = vectorizer.fit_transform(posts).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.59 s, sys: 11.3 s, total: 20.9 s\n",
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%time cos_sim = 1 - pairwise_distances(vect, vect, \"cosine\", n_jobs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_posts(sim, ri, n, users, posts):\n",
    "    top_n = list(range(-1,-n-1,-1))\n",
    "    doc = sim[ri, :]\n",
    "    doc_sort = np.argsort(doc)\n",
    "    doc_sort = doc_sort[0:-1]\n",
    "    user = users[ri]\n",
    "    sim_users = doc_sort[top_n]\n",
    "    return (user, posts[ri]), [(users[sim], posts[sim]) for sim in sim_users]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** sorting all the columns and rows takes a while and is unnecessary for this step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('anxiousman ', 'have you had these feelings yourself then if you smoke'),\n",
       " [('Pebbles ',\n",
       "   'its when im alone only i want to be alone its so confusing my feelings are always up and down its so tiring and confusing'),\n",
       "  ('Lincoln1990 ', 'my feelings are hurt'),\n",
       "  ('Rock_warlock ',\n",
       "   'yeahsir i shouldnt be that serious about lovemay be im not mature enough but if you are having feelings for her  naturally may be because she is beautiful   i think its too early to take feelings so seriously '),\n",
       "  ('Spidergirl ', 'i feel your pain i have the same feelings'),\n",
       "  ('Rachy17 ', 'feel all trembly and tense horrible feelings')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_posts(cos_sim, 40, 5, users, posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using naive bayes classifier to help classify responder posts that are personal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data ready for Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- make assumption about what is personal and not personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load pkl file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#is anx_post df with manual labels\n",
    "df = pd.read_pickle(\"df_man.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**split into auth and responder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = df[df['post_type'] == 'author']\n",
    "res = df[df['post_type'] == 'responder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**split responder df into 2dfs - 1) contain a personal regex string, 2) does not contain regex string**\n",
    "\n",
    "**relabel personal responders as 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_per = res[res['post'].str.contains(\"(i feel|im feeling|im worried|my anxiety|i have felt)\", regex = True)]\n",
    "res_no = res.drop(res_per.index)\n",
    "\n",
    "res_per['label'] = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**merge author df and the responder df that contains personal posts** \n",
    "\n",
    "**relabel other df of responders that does not contain personal regex string** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#know the type of post\n",
    "df_know = pd.concat([auth, res_per])\n",
    "df_know.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#responders do not contain regex string\n",
    "df_res = res_no\n",
    "df_res.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter responder df so that it will only contain impersonal posts**\n",
    "\n",
    "**create a new df of responders where i'm uncertain about the content of post called df_predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_to_remove = []\n",
    "for i,p in enumerate(df_res['post']):\n",
    "    len_doc = len(p.split())\n",
    "    if len(p.split()) == 0:\n",
    "        indices_to_remove.append(i)\n",
    "        continue\n",
    "        \n",
    "    numi = p.split().count(\"i\") + p.split().count(\"im\")\n",
    "    numyou = p.split().count(\"you\")+ p.split().count(\"your\") + p.split().count(\"youre\") + p.split().count(\"u\")\n",
    "    i_rate = numi/len_doc\n",
    "    you_rate = numyou/len_doc\n",
    "    \n",
    "    if df_res['label'][i] == 0:\n",
    "        continue\n",
    "    elif (i_rate > you_rate):\n",
    "        indices_to_remove.append(i)\n",
    "    elif (i_rate > you_rate):\n",
    "        indices_to_remove.append(i)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "df_predict = pd.concat([df_res.iloc[indices_to_remove]])\n",
    "df_res.drop(df.index[[indices_to_remove]], inplace = True)\n",
    "df_res.reset_index(drop= True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out authors who don't have any 1st person pronouns and add to df_predict (uncertain)**\n",
    "\n",
    "**Create df_know (have a good idea of content of post - personal or not)**\n",
    "\n",
    "**df_know - used to train Naive Bayes**\n",
    "\n",
    "**df_predict - used to predict other responses**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_to_remove = []\n",
    "for i,p in enumerate(df_know['post']):\n",
    "    if p.split().count(\"i\") + p.split().count(\"im\") == 0:\n",
    "        author_to_remove.append(i)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "        \n",
    "df_predict = pd.concat([df_predict, df_know.iloc[author_to_remove]])\n",
    "df_know.drop(df_know.index[[author_to_remove]], inplace = True)\n",
    "\n",
    "df_know = pd.concat([df_know, df_res])\n",
    "df_know.reset_index(drop = True, inplace = True)\n",
    "\n",
    "df_predict.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at value counts of my labels in df_know**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19853\n",
       "0    11395\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_know['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create docs and find word counts for NB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create docs\n",
    "docs = [df_know['post'][i] for i in range(0,len(df_know))]\n",
    "\n",
    "#get tokens\n",
    "tokens = set()\n",
    "for doc in docs:\n",
    "    tokens.update(doc.split())\n",
    "    \n",
    "tokens_list = list(tokens)\n",
    "\n",
    "vocab_dict = {word: i for i, word in enumerate(tokens_list)}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "word_counts = np.zeros((len(docs), len(tokens)))\n",
    "for doc_id, words in enumerate(docs):\n",
    "    for word in words.split():\n",
    "        word_id = vocab_dict[word]\n",
    "        word_counts[doc_id][word_id] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create Naive Bayes instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train,Test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = word_counts\n",
    "y = np.array(df_know['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test model accuracy (based on assumptions i already made)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89695999999999998"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict on uncertain responders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create docs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = df_predict['post']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get word counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "word_counts = np.zeros((len(docs), len(tokens)))\n",
    "for doc_id, words in enumerate(docs):\n",
    "    for word in words.split():\n",
    "        if word not in vocab_dict:\n",
    "            continue\n",
    "        else:\n",
    "            word_id = vocab_dict[word]\n",
    "            word_counts[doc_id][word_id] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**soft classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = word_counts\n",
    "\n",
    "labels_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hard classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = clf.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**drop hold labels which are just 9 for uncertain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict.drop(\"label\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add predicted soft and hard labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict['hard'] = labels\n",
    "df_predict['soft'] = labels_proba[:,0]\n",
    "df_predict.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>user</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post</th>\n",
       "      <th>post_type</th>\n",
       "      <th>mood</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>forum_name</th>\n",
       "      <th>hard</th>\n",
       "      <th>soft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1592736</td>\n",
       "      <td>Zardos</td>\n",
       "      <td>nan</td>\n",
       "      <td>i can sympathize i get crippling anxiety when i go to bed and first thing on a morning it gets better during the day when im busy and then at night i dont want to get into bed   has anything chang...</td>\n",
       "      <td>responder</td>\n",
       "      <td>nan</td>\n",
       "      <td>Sudden Onset Anxiety - Please help!</td>\n",
       "      <td>Generalized Anxiety Disorder</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>585119</td>\n",
       "      <td>Mayfair</td>\n",
       "      <td>nan</td>\n",
       "      <td>great tune  i had my beatles number one hits in my car last week they are genius with chords thats their secret but only weirdos like me recognise it my car got broke into last week and they empti...</td>\n",
       "      <td>responder</td>\n",
       "      <td>nan</td>\n",
       "      <td>didnt know where to post this</td>\n",
       "      <td>Social Anxiety</td>\n",
       "      <td>0</td>\n",
       "      <td>0.953017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>586791</td>\n",
       "      <td>Ainsworth11</td>\n",
       "      <td>nan</td>\n",
       "      <td>why did i post this in social anxiety ah well never mind   i got some sleepers from boots yesterday slept for 4 hours but felt i had been hit round the head with a baseball bat when i woke up as y...</td>\n",
       "      <td>responder</td>\n",
       "      <td>nan</td>\n",
       "      <td>didnt know where to post this</td>\n",
       "      <td>Social Anxiety</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1599105</td>\n",
       "      <td>Macka</td>\n",
       "      <td>nan</td>\n",
       "      <td>hi ark   i also love writing something in me since i can remember when i was in the beginnings of my breakdown i wrote 30000 words in ten days  my pc permanently crashed and so did my brain   when...</td>\n",
       "      <td>responder</td>\n",
       "      <td>Inspired</td>\n",
       "      <td>Is this GAD? My mind keeps creating associations between things and anxiety, and they're ruining my life!</td>\n",
       "      <td>Generalized Anxiety Disorder</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>586857</td>\n",
       "      <td>wendolene26</td>\n",
       "      <td>nan</td>\n",
       "      <td>the beatles help album was the first cd album i got given when my parents bought my a cd player hifi  i was learning guitar and playing a lot of the beatles tunes as they have easy chords so i sup...</td>\n",
       "      <td>responder</td>\n",
       "      <td>Paranoid</td>\n",
       "      <td>didnt know where to post this</td>\n",
       "      <td>Social Anxiety</td>\n",
       "      <td>0</td>\n",
       "      <td>0.701172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>589807</td>\n",
       "      <td>Ainsworth11</td>\n",
       "      <td>nan</td>\n",
       "      <td>seroqueltis all looking for understanding and i get a drug</td>\n",
       "      <td>responder</td>\n",
       "      <td>nan</td>\n",
       "      <td>didnt know where to post this</td>\n",
       "      <td>Social Anxiety</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1598695</td>\n",
       "      <td>blacksmoke</td>\n",
       "      <td>nan</td>\n",
       "      <td>hello janey1966 hey janey yeah the second half of life stinks i am really seeing my mother for who she really is fooled myself for the first half  really sorry for what you are going through yeah ...</td>\n",
       "      <td>responder</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Feeling More Anxious The Older I Get.  I Am 51.</td>\n",
       "      <td>Generalized Anxiety Disorder</td>\n",
       "      <td>0</td>\n",
       "      <td>0.908417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1598189</td>\n",
       "      <td>frogsplash</td>\n",
       "      <td>nan</td>\n",
       "      <td>hi i would recommend watching some youtube videos regarding dealing with anxiety and worrying less</td>\n",
       "      <td>responder</td>\n",
       "      <td>nan</td>\n",
       "      <td>feeling anxious</td>\n",
       "      <td>Generalized Anxiety Disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>536359</td>\n",
       "      <td>yesican</td>\n",
       "      <td>nan</td>\n",
       "      <td>i wish it was just one beer one beer doesnt do anything for me it starts with a beer then two then three and so on i dont get drunk but i definitely do drink too much its not good for my health me...</td>\n",
       "      <td>responder</td>\n",
       "      <td>Blah</td>\n",
       "      <td>social anxiety... causing me to drink too much</td>\n",
       "      <td>Social Anxiety</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>536365</td>\n",
       "      <td>yesican</td>\n",
       "      <td>nan</td>\n",
       "      <td>no i am sure that we havent spoken before this is my first time talking about this on a forum</td>\n",
       "      <td>responder</td>\n",
       "      <td>Blah</td>\n",
       "      <td>social anxiety... causing me to drink too much</td>\n",
       "      <td>Social Anxiety</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pid          user post_title  \\\n",
       "0  1592736       Zardos         nan   \n",
       "1   585119      Mayfair         nan   \n",
       "2   586791   Ainsworth11        nan   \n",
       "3  1599105        Macka         nan   \n",
       "4   586857  wendolene26         nan   \n",
       "5   589807   Ainsworth11        nan   \n",
       "6  1598695   blacksmoke         nan   \n",
       "7  1598189   frogsplash         nan   \n",
       "8   536359      yesican         nan   \n",
       "9   536365      yesican         nan   \n",
       "\n",
       "                                                                                                                                                                                                      post  \\\n",
       "0  i can sympathize i get crippling anxiety when i go to bed and first thing on a morning it gets better during the day when im busy and then at night i dont want to get into bed   has anything chang...   \n",
       "1  great tune  i had my beatles number one hits in my car last week they are genius with chords thats their secret but only weirdos like me recognise it my car got broke into last week and they empti...   \n",
       "2  why did i post this in social anxiety ah well never mind   i got some sleepers from boots yesterday slept for 4 hours but felt i had been hit round the head with a baseball bat when i woke up as y...   \n",
       "3  hi ark   i also love writing something in me since i can remember when i was in the beginnings of my breakdown i wrote 30000 words in ten days  my pc permanently crashed and so did my brain   when...   \n",
       "4  the beatles help album was the first cd album i got given when my parents bought my a cd player hifi  i was learning guitar and playing a lot of the beatles tunes as they have easy chords so i sup...   \n",
       "5                                                                                                                                               seroqueltis all looking for understanding and i get a drug   \n",
       "6  hello janey1966 hey janey yeah the second half of life stinks i am really seeing my mother for who she really is fooled myself for the first half  really sorry for what you are going through yeah ...   \n",
       "7                                                                                                       hi i would recommend watching some youtube videos regarding dealing with anxiety and worrying less   \n",
       "8  i wish it was just one beer one beer doesnt do anything for me it starts with a beer then two then three and so on i dont get drunk but i definitely do drink too much its not good for my health me...   \n",
       "9                                                                                                           no i am sure that we havent spoken before this is my first time talking about this on a forum    \n",
       "\n",
       "   post_type      mood  \\\n",
       "0  responder       nan   \n",
       "1  responder       nan   \n",
       "2  responder       nan   \n",
       "3  responder  Inspired   \n",
       "4  responder  Paranoid   \n",
       "5  responder       nan   \n",
       "6  responder       Sad   \n",
       "7  responder       nan   \n",
       "8  responder      Blah   \n",
       "9  responder      Blah   \n",
       "\n",
       "                                                                                                thread_title  \\\n",
       "0                                                                        Sudden Onset Anxiety - Please help!   \n",
       "1                                                                              didnt know where to post this   \n",
       "2                                                                              didnt know where to post this   \n",
       "3  Is this GAD? My mind keeps creating associations between things and anxiety, and they're ruining my life!   \n",
       "4                                                                              didnt know where to post this   \n",
       "5                                                                              didnt know where to post this   \n",
       "6                                                            Feeling More Anxious The Older I Get.  I Am 51.   \n",
       "7                                                                                            feeling anxious   \n",
       "8                                                             social anxiety... causing me to drink too much   \n",
       "9                                                             social anxiety... causing me to drink too much   \n",
       "\n",
       "                     forum_name  hard      soft  \n",
       "0  Generalized Anxiety Disorder     0  1.000000  \n",
       "1                Social Anxiety     0  0.953017  \n",
       "2                Social Anxiety     0  0.999999  \n",
       "3  Generalized Anxiety Disorder     0  1.000000  \n",
       "4                Social Anxiety     0  0.701172  \n",
       "5                Social Anxiety     0  0.513875  \n",
       "6  Generalized Anxiety Disorder     0  0.908417  \n",
       "7  Generalized Anxiety Disorder     1  0.361373  \n",
       "8                Social Anxiety     0  1.000000  \n",
       "9                Social Anxiety     0  0.906220  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth' , 200)\n",
    "df_predict.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messing around with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = ['joe', 'mary', 'bill']\n",
    "docs = ['hey there trying to find my friend friend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer1 = TfidfVectorizer(stop_words = 'english')\n",
    "vect1 = vectorizer1.fit_transform(docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.81649658,  0.40824829,  0.40824829]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'friend': 0, 'hey': 1, 'trying': 2}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_kernel(vect1, vect1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(stop_words = 'english', ngram_range = (1,2))\n",
    "vect2 = vectorizer2.fit_transform(docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35409974,  0.35409974,  0.35409974,  0.35409974,  0.35409974,\n",
       "         0.49767483,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.35409974,  0.        ],\n",
       "       [ 0.25096919,  0.25096919,  0.25096919,  0.25096919,  0.25096919,\n",
       "         0.        ,  0.35272845,  0.35272845,  0.35272845,  0.35272845,\n",
       "         0.25096919,  0.35272845]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.53320876],\n",
       "       [ 0.53320876,  1.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_kernel(vect2, vect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
